{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b79d81fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T22:02:26.789021Z",
     "start_time": "2021-11-15T22:02:22.787855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import cv2\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import imshowpair\n",
    "import copy\n",
    "import glob\n",
    "import jupyternotify\n",
    "import re\n",
    "import imutils\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy = True\n",
    "\n",
    "ip = get_ipython()\n",
    "ip.register_magics(jupyternotify.JupyterNotifyMagics)\n",
    "%autonotify -a 120\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [30, 15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d8135b",
   "metadata": {},
   "source": [
    "# Loading in the Two Camera's RGB-D Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee0a6849",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T22:19:38.697672Z",
     "start_time": "2021-11-15T22:19:32.972909Z"
    }
   },
   "outputs": [],
   "source": [
    "# For sorting the images\n",
    "def get_key(fp):\n",
    "    filename = os.path.splitext(os.path.basename(fp))[0]\n",
    "    int_part = filename.split()[0]\n",
    "    int_part = int_part.split('.')[0]\n",
    "    return int(int_part)\n",
    "#----------------------------------------------------------\n",
    "# For loading the images\n",
    "def load_images(path, is_depth = False):\n",
    "    frames = []\n",
    "    if is_depth:\n",
    "        files = glob.glob (path + \"/*.png\")\n",
    "    else:\n",
    "        files = glob.glob (path + \"/*.jpg\")\n",
    "    \n",
    "    files = sorted(files, key=get_key)\n",
    "    for myFile in files:\n",
    "        image = cv2.imread(myFile)\n",
    "        frames.append (image)\n",
    "    frames = np.array(frames)\n",
    "    return frames\n",
    "#----------------------------------------------------------    \n",
    "\n",
    "rgb_top_path = '/var/Programs/Data/Cotton Imaging/18_9_top_RTabMap_Images/18_9_top_rgb'\n",
    "depth_top_path = '/var/Programs/Data/Cotton Imaging/18_9_top_RTabMap_Images/18_9_top_depth'\n",
    "rgb_bot_path = '/var/Programs/Data/Cotton Imaging/18_9_bot_RTabMap_Images/18_9_bot_left'\n",
    "depth_bot_path = '/var/Programs/Data/Cotton Imaging/18_9_bot_RTabMap_Images/18_9_bot_depth'\n",
    "\n",
    "rgb_top_images = load_images(rgb_top_path)\n",
    "depth_top_images = load_images(depth_top_path, True)\n",
    "rgb_bot_images = load_images(rgb_bot_path)\n",
    "depth_bot_images = load_images(depth_bot_path, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f23f661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T22:19:46.829288Z",
     "start_time": "2021-11-15T22:19:46.802212Z"
    }
   },
   "source": [
    "# Function for Stitching the RGB-D Images of one Camera using SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "08ca8512",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-16T00:29:37.170085Z",
     "start_time": "2021-11-16T00:29:37.128238Z"
    }
   },
   "outputs": [],
   "source": [
    "def stitch_rgbd(rgb_images, depth_images):\n",
    "    img_1 = rgb_images[0]\n",
    "    output_rgb = rgb_images[0]\n",
    "    img_1_depth = depth_images[0]\n",
    "    output_depth = depth_images[0]\n",
    "    img1 = cv2.cvtColor(img_1,cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    for i in range(1, len(rgb_images)):\n",
    "        img_2 = rgb_images[i]\n",
    "        img_2_depth = depth_images[i]\n",
    "        img2 = cv2.cvtColor(img_2,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        kp1, des1 = sift.detectAndCompute(img1[:,:img_2.shape[1]],None)\n",
    "        kp2, des2 = sift.detectAndCompute(img2,None)\n",
    "        \n",
    "        # Brute-Force Matcher using L2-norm as measurement tool\n",
    "        bf = cv2.BFMatcher()\n",
    "        \n",
    "        # Finds the k best matches for each descriptor from a query set.\n",
    "        matches = bf.knnMatch(des1,des2, k=2)\n",
    "        \n",
    "        # Applying the Ratio Test by D. Lowe\n",
    "        if len(matches) > 6000:\n",
    "            ratio = 0.8\n",
    "        elif len(matches) <= 6000 and len(matches) >4650:\n",
    "            ratio = 0.5\n",
    "        else:\n",
    "            ratio = 0.7\n",
    "        \n",
    "        good = []\n",
    "        for m in matches:\n",
    "            if (m[0].distance < ratio*m[1].distance):\n",
    "                good.append(m)\n",
    "        matches = np.asarray(good)\n",
    "\n",
    "        if (len(matches[:,0]) >= 4):\n",
    "            src = np.float32([ kp1[m.queryIdx].pt for m in matches[:,0] ]).reshape(-1,1,2)\n",
    "            dst = np.float32([ kp2[m.trainIdx].pt for m in matches[:,0] ]).reshape(-1,1,2)\n",
    "            H, masked = cv2.findHomography(src, dst, cv2.RANSAC, 5.0)\n",
    "        else:\n",
    "            print(f\"For image #{i}\")\n",
    "            raise AssertionError('Canâ€™t find enough keypoints.')\n",
    "        \n",
    "        print(f\"Image #{i}\")\n",
    "        # RGB Stitching\n",
    "        dst = cv2.warpPerspective(img_1,H,((img_1.shape[1]+ img_2.shape[1]), img_2.shape[0])) #wraped image\n",
    "        dst[0:img_2.shape[0], 0:img_2.shape[1]] = img_2 #stitched image\n",
    "\n",
    "        # Depth Stitching\n",
    "        dst_depth = cv2.warpPerspective(img_1_depth,H,((img_1.shape[1] + img_2.shape[1]), img_2.shape[0])) #wraped image\n",
    "        dst_depth[0:img_2.shape[0], 0:img_2.shape[1]]= img_2_depth #stitched image\n",
    "        \n",
    "        if i % 3 == 0 :\n",
    "            dst_gray = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n",
    "            indices = np.argwhere(dst_gray[360,:] == 0)[30]\n",
    "            output_rgb = dst[:,:indices[0]]\n",
    "            output_depth = dst_depth[:,:indices[0]]\n",
    "        else:\n",
    "            output_rgb = dst\n",
    "            output_depth = dst_depth\n",
    "            \n",
    "        if i != len(rgb_images) - 1:\n",
    "            # Just looking at the previous image\n",
    "            img_1 = output_rgb\n",
    "            img_1_depth = output_depth\n",
    "            img1 = cv2.cvtColor(img_1,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    return output_rgb, output_depth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9b1e8f",
   "metadata": {},
   "source": [
    "## Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "71f29231",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-16T00:31:42.392428Z",
     "start_time": "2021-11-16T00:29:39.650992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image #1\n",
      "Image #2\n",
      "Image #3\n",
      "Image #4\n",
      "Image #5\n",
      "Image #6\n",
      "Image #7\n",
      "Image #8\n",
      "Image #9\n",
      "Image #10\n",
      "Image #11\n",
      "Image #12\n",
      "Image #13\n",
      "Image #14\n",
      "Image #15\n",
      "Image #16\n",
      "Image #17\n",
      "Image #18\n",
      "Image #19\n",
      "Image #20\n",
      "Image #21\n",
      "Image #22\n",
      "Image #23\n",
      "Image #24\n",
      "Image #25\n",
      "Image #26\n",
      "Image #27\n",
      "Image #28\n",
      "Image #29\n",
      "Image #30\n",
      "Image #31\n",
      "Image #32\n",
      "Image #33\n",
      "Image #34\n",
      "Image #35\n",
      "Image #36\n",
      "Image #37\n",
      "Image #38\n",
      "Image #39\n",
      "Image #40\n",
      "Image #41\n",
      "Image #42\n",
      "Image #43\n",
      "Image #44\n",
      "Image #45\n",
      "Image #46\n",
      "Image #47\n",
      "Image #48\n",
      "Image #49\n",
      "Image #50\n",
      "Image #51\n",
      "Image #52\n",
      "Image #53\n",
      "Image #54\n",
      "Image #55\n",
      "Image #56\n",
      "Image #57\n",
      "Image #58\n",
      "Image #59\n",
      "Image #60\n",
      "Image #61\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"17ea1c02-36c7-4ff1-803f-602d6640f430\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"17ea1c02-36c7-4ff1-803f-602d6640f430\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Cell Execution Has Finished!!\", \"autonotify_after\": \"120\", \"autonotify_output\": false};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_rgb, top_depth = stitch_rgbd(rgb_top_images[:62], depth_top_images[:62])\n",
    "\n",
    "cv2.imwrite('top_rgb.jpg', top_rgb)\n",
    "cv2.imwrite('top_depth.png', top_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e219177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "or i == len(rgb_images) - 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd0206a7a580e2fe49e54ef049f7768a09700fa34f7f0a0efcdd54a0a72196c0b8b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
